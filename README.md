   * We purpose here an example of multivariate analysis used for feature selection. See the notebook: [shape-features](https://github.com/danielaterra/shape-features/tree/main)/[statistical_analysis_for_feature_selection](https://github.com/danielaterra/shape-features/tree/main/statistical_analysis_for_feature_selection/MV_shapeFeatures_versao2.ipynb) .  
   * With the **7 selected features** we run the same classification models of our previous paper ([LastPaperTerra2023.pdf](https://github.com/danielaterra/shape-features/files/15493240/LastPaperTerra2023.pdf)).
   * The same results (or better) was achieved for almost all classifiers without using **Upsample** for data augmentation! Check the notebooks:
     - Plain classification - results for 2, 3 and 6 classes  here  [classification_plain.ipynb](https://github.com/danielaterra/shape-features/blob/main/statistical_analysis_for_feature_selection/classification_plain.ipynb)
     - Hierarquical classification - results for 2, 3 and 6 classes here [classification_hierarq.ipynb](https://github.com/danielaterra/shape-features/blob/main/statistical_analysis_for_feature_selection/classification_hierarq.ipynb)
